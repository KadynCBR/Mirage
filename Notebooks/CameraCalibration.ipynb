{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78fd15d-71e6-45ab-bd02-9aeb24253fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top squares -> :10 - 1:45\n",
    "# Top arcos -> 1:47 - 2:47\n",
    "# bottom squares -> 2:50 - 3:50\n",
    "# bottom arcos -> 3:53 - 4:46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd76737a-0377-4105-873e-2041daff0b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np  \n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from mirage.mirage_helpers import *\n",
    "\n",
    "def showim(im):\n",
    "    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "\n",
    "def show_images(images, cols = 1, titles = None):\n",
    "    \"\"\"Display a list of images in a single figure with matplotlib.\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    images: List of np.arrays compatible with plt.imshow.\n",
    "    \n",
    "    cols (Default = 1): Number of columns in figure (number of rows is \n",
    "                        set to np.ceil(n_images/float(cols))).\n",
    "    \n",
    "    titles: List of titles corresponding to each image. Must have\n",
    "            the same length as titles.\n",
    "    \"\"\"\n",
    "    assert((titles is None)or (len(images) == len(titles)))\n",
    "    n_images = len(images)\n",
    "    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n",
    "    fig = plt.figure()\n",
    "    for n, (image, title) in enumerate(zip(images, titles)):\n",
    "        a = fig.add_subplot(cols, int(np.ceil(n_images/float(cols))), n + 1)\n",
    "        if image.ndim == 2:\n",
    "            plt.gray()\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        a.set_title(title)\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n",
    "    plt.show()\n",
    "\n",
    "def GetFrameFromVideo(filepath, framenumber):\n",
    "    _cap = cv2.VideoCapture(filepath)\n",
    "    _cap.set(cv2.CAP_PROP_POS_FRAMES, framenumber)\n",
    "    ret, frame = _cap.read()\n",
    "    return ret, frame\n",
    "\n",
    "number_of_squares_X = 10\n",
    "number_of_squares_y = 7\n",
    "nX = number_of_squares_X - 1 \n",
    "nY = number_of_squares_y - 1\n",
    "square_size = 0.025 # 1 inch in meters\n",
    "\n",
    "# For calibrating front camera\n",
    "camera_angle = \"front\"\n",
    "filepath = \"../../top_square.mp4\"\n",
    "\n",
    "# for calibrating side camera\n",
    "# camera_angle = \"side\"\n",
    "# filepath = \"../../bottom_squares.mp4\"\n",
    "\n",
    "def crophelpr(img):\n",
    "    if camera_angle == \"front\":\n",
    "        frame = crop_image(img, 0, 720, 0, 1280, 0)\n",
    "    else:\n",
    "        frame = crop_image(img, 720, 720, 0, 1280, 0)\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae65bc8-0394-4319-9c32-7d38fa33e2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Example Read\n",
    "# cap = cv2.VideoCapture(filepath)\n",
    "# flag, frame = cap.read()\n",
    "# frame = crophelpr(frame)\n",
    "# gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# success, corners = cv2.findChessboardCorners(gray, (nY, nX), None)\n",
    "# chessboard = frame.copy()\n",
    "# cv2.drawChessboardCorners(chessboard, (nY, nX), corners, success)\n",
    "# print(success)\n",
    "# show_images([frame, gray, chessboard], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613ec0d8-cbc4-4028-bc03-ccbfd216d2b3",
   "metadata": {},
   "source": [
    "# Calibration routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4055c499-acc4-438b-84d6-7d8512b9c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store vector of 3D points for all chessboard images ( World coordinant frame )\n",
    "object_points = []\n",
    "# store vector of 2D points for all chessboard images ( Camera coordinant frame )\n",
    "image_points = []\n",
    "\n",
    "# set termination criteria, we stop when accuracy is reached or a certain number of iterations\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Define real world coordinants for points in the 3D coordinant frame\n",
    "# Object points are (0, 0, 0,), (1, 0, 0), (2, 0, 0), ....., (5, 8, 0) ?\n",
    "object_points_3D = np.zeros((nX * nY, 3), np.float32)\n",
    "\n",
    "# these are the x and y coordinants\n",
    "object_points_3D[:,:2] = np.mgrid[0:nY, 0:nX].T.reshape(-1,2)\n",
    "\n",
    "object_points_3D = object_points_3D * square_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957a3bba-4c4e-4109-9387-8b46666e473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image in images:  # or while loop over the video.\n",
    "from tqdm.notebook import tqdm\n",
    "cap = cv2.VideoCapture(filepath)\n",
    "framelist = []\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "current_frame = 0\n",
    "usable_checkboards = 0\n",
    "for framenum in tqdm(range(length)):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        break\n",
    "    frame = crophelpr(frame)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    success, corners = cv2.findChessboardCorners(gray, (nY, nX), None)\n",
    "    if success:\n",
    "        object_points.append(object_points_3D)\n",
    "        corners_2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "        image_points.append(corners_2)\n",
    "        usable_checkboards += 1\n",
    "\n",
    "# Calibrate here using above chessboards\n",
    "print(f\"Performing calibration using {usable_checkboards} images\") \n",
    "height, width = frame.shape[:2]\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(object_points, image_points, gray.shape[::-1], None, None)\n",
    "optimal_camera_matrix, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (width, height), 1, (width, height))\n",
    "\n",
    "mean_error = 0\n",
    "for i in tqdm(range(len(object_points))):\n",
    "    imgpoints2, _ = cv2.projectPoints(object_points[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv2.norm(image_points[i], imgpoints2, cv2.NORM_L2)/len(imgpoints2)\n",
    "    mean_error += error\n",
    "print( f\"Total usable images {usable_checkboards}\")\n",
    "print( f\"total error: {mean_error/len(object_points)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75655b36-3100-4add-9d34-f17c84fcc9b9",
   "metadata": {},
   "source": [
    "# Test using a frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93317c0-7916-4fe9-9b78-78d727596cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distframenum = 55\n",
    "# ret, distorted_image = GetFrameFromVideo(filepath, distframenum)\n",
    "# distorted_image = crophelpr(distorted_image)\n",
    "# undistorted_image = cv2.undistort(distorted_image, mtx, dist, None, optimal_camera_matrix)\n",
    "\n",
    "# graydist = cv2.cvtColor(distorted_image, cv2.COLOR_BGR2GRAY)\n",
    "# success, cornersdist = cv2.findChessboardCorners(graydist, (nY, nX), None)\n",
    "# chessboarddist = distorted_image.copy()\n",
    "# cv2.drawChessboardCorners(chessboarddist, (nY, nX), cornersdist, success)\n",
    "\n",
    "\n",
    "# grayundist = cv2.cvtColor(undistorted_image, cv2.COLOR_BGR2GRAY)\n",
    "# success, cornersundist = cv2.findChessboardCorners(grayundist, (nY, nX), None)\n",
    "# chessboardundist = undistorted_image.copy()\n",
    "# cv2.drawChessboardCorners(chessboardundist, (nY, nX), cornersundist, success)\n",
    "\n",
    "# show_images([distorted_image, undistorted_image, chessboarddist, chessboardundist], 2, [\"dist\", \"undist\", \"cdist\", \"cundist\"])\n",
    "# cv2.imwrite(\"calibOut/a.png\", distorted_image)\n",
    "# cv2.imwrite(\"calibOut/b.png\", undistorted_image)\n",
    "# cv2.imwrite(\"calibOut/c.png\", chessboarddist)\n",
    "# cv2.imwrite(\"calibOut/d.png\", chessboardundist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b414356-ccbd-4cff-af2e-d563fdf37bc1",
   "metadata": {},
   "source": [
    "# Save the calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb99500d-0031-40a5-9ceb-34b157021503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "calib_result_pickle = {}\n",
    "calib_result_pickle[\"mtx\"] = mtx\n",
    "calib_result_pickle[\"optimal_camera_matrix\"] = optimal_camera_matrix\n",
    "calib_result_pickle[\"dist\"] = dist\n",
    "calib_result_pickle[\"rvecs\"] = rvecs\n",
    "calib_result_pickle[\"tvecs\"] = tvecs\n",
    "pickle.dump(calib_result_pickle, open(f\"{camera_angle}_camera_calib_pickle.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaa2605-af74-4756-b2f2-6d2c9d21f9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MirageEnv",
   "language": "python",
   "name": "mirageenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
