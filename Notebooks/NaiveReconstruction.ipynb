{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668b5a5e-efc7-4190-8757-739512206311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from typing import Any\n",
    "import subprocess\n",
    "import os\n",
    "from cv2.typing import MatLike\n",
    "from argparse import ArgumentParser\n",
    "import numpy as np\n",
    "from mirage.mirage_helpers import *\n",
    "from mirage.pose_extract_base import MLAbstractInterface\n",
    "from mirage.rgb_interface import CameraInterface\n",
    "from mirage.movenet import MovenetInterface\n",
    "from mirage.skeleton import SkeletonDetection\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def showim(im):\n",
    "    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "\n",
    "def show_images(images, cols = 1, titles = None):\n",
    "    \"\"\"Display a list of images in a single figure with matplotlib.\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    images: List of np.arrays compatible with plt.imshow.\n",
    "    \n",
    "    cols (Default = 1): Number of columns in figure (number of rows is \n",
    "                        set to np.ceil(n_images/float(cols))).\n",
    "    \n",
    "    titles: List of titles corresponding to each image. Must have\n",
    "            the same length as titles.\n",
    "    \"\"\"\n",
    "    assert((titles is None)or (len(images) == len(titles)))\n",
    "    n_images = len(images)\n",
    "    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n",
    "    fig = plt.figure()\n",
    "    for n, (image, title) in enumerate(zip(images, titles)):\n",
    "        a = fig.add_subplot(cols, int(np.ceil(n_images/float(cols))), n + 1)\n",
    "        if image.ndim == 2:\n",
    "            plt.gray()\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        a.set_title(title)\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6517346a-25f8-411d-ad0f-a0b70f0e0f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "def ost_to_np(filename):\n",
    "    with open(filename) as s:\n",
    "        try:\n",
    "            q = yaml.safe_load(s)\n",
    "            return {\n",
    "                \"image_width\": q[\"image_width\"],\n",
    "                \"image_height\": q[\"image_height\"],\n",
    "                \"camera_name\": q[\"camera_name\"],\n",
    "                \"camera_matrix\": np.array(q[\"camera_matrix\"][\"data\"]).reshape(\n",
    "                    (q[\"camera_matrix\"][\"rows\"], q[\"camera_matrix\"][\"cols\"])\n",
    "                ),\n",
    "                \"distortion_coefficients\": np.array(q[\"distortion_coefficients\"][\"data\"]).reshape(\n",
    "                    (q[\"distortion_coefficients\"][\"rows\"], q[\"distortion_coefficients\"][\"cols\"])\n",
    "                ),\n",
    "            }\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "            return None\n",
    "\n",
    "\n",
    "def process_and_viz_split(i_cam: CameraInterface, ml_interface: MLAbstractInterface) -> MatLike:\n",
    "    img = i_cam.get_next_frame()\n",
    "    img_a, img_b = split_image_stack(img)\n",
    "    a_crop = determine_crop_region(s_a, img_a.shape[0], img_a.shape[1])\n",
    "    b_crop = determine_crop_region(s_b, img_b.shape[0], img_b.shape[1])\n",
    "    img_a_kp = ml_interface.predict(img_a, a_crop)\n",
    "    img_b_kp = ml_interface.predict(img_b, b_crop)\n",
    "    s_a.update_predictions(img_a_kp, (1.0 / i_cam.get_frame_rate_per_second()))\n",
    "    s_b.update_predictions(img_b_kp, (1.0 / i_cam.get_frame_rate_per_second()))\n",
    "    img_a_viz = skeleton_to_image(img_a, s_a)\n",
    "    img_b_viz = skeleton_to_image(img_b, s_b)\n",
    "    return stack_image(img_a_viz, img_b_viz)\n",
    "\n",
    "\n",
    "def process_and_viz(i_cam: CameraInterface, ml_interface: MLAbstractInterface) -> MatLike:\n",
    "    img = i_cam.get_next_frame()\n",
    "    img_kp = ml_interface.predict(img)\n",
    "    s_a.update_predictions(img_kp, (1.0 / i_cam.get_frame_rate_per_second()))\n",
    "    img_viz = skeleton_to_image(img, s_a)\n",
    "    return img_viz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f277d570-1c16-4044-9cd3-d2f863f2d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"../../Data/Reference_Parayno_Jeru.mp4\"\n",
    "frame_number_start = 0\n",
    "frame_number_end = 160\n",
    "frames = []\n",
    "splitimage = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de973825-0ef8-4e8f-be4d-ae4afb2944f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "ml_interface = MovenetInterface()\n",
    "s_a = SkeletonDetection()\n",
    "s_b = SkeletonDetection()\n",
    "i_cam = CameraInterface(input_file)\n",
    "i_cam.set_frame(frame_number_start)\n",
    "frame_number_end = frame_number_end if frame_number_end != 0 else i_cam.get_total_frames()\n",
    "##### reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837b936e-f495-48b6-949f-5ca10bffde8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_log_info(im: MatLike, skele: SkeletonDetection):\n",
    "    img = im.copy()\n",
    "    num_joints = len(skele.joints)\n",
    "    print(num_joints)\n",
    "    starting_y = 150\n",
    "    starting_x = im.shape[1]-350\n",
    "    height_per_text = 30\n",
    "    img = overlay_rect(img, starting_x - 30, 20, im.shape[1] - starting_x+20, im.shape[0] - 40)\n",
    "    for j in skele.joints.values():\n",
    "        out = f\"{j.name}: {j.confidence*100:.0f}%\"\n",
    "        img = cv2.putText(img, f\"{out:<20}\", (starting_x, starting_y), cv2.FONT_HERSHEY_PLAIN, 2, (255,0,255), 2)\n",
    "        starting_y += height_per_text\n",
    "    return img\n",
    "\n",
    "def overlay_rect(img: MatLike, x: int, y: int, w: int, h: int):\n",
    "    # First we crop the sub-rect from the image\n",
    "    sub_img = img[y:y+h, x:x+w]\n",
    "    white_rect = np.ones(sub_img.shape, dtype=np.uint8) * 0\n",
    "    res = cv2.addWeighted(sub_img, 0.25, white_rect, 0.75, 1.0)\n",
    "    # Putting the image back to its position\n",
    "    img[y:y+h, x:x+w] = res\n",
    "    return img\n",
    "\n",
    "def merge_skeleton(image: MatLike, skeleton_front: SkeletonDetection, skeleton_side: SkeletonDetection):\n",
    "    homogenous_skeleton = {}\n",
    "    for k in skeleton_front.joints.keys():\n",
    "        x, _, y, _ = skeleton_front.joints[k].estimate\n",
    "        x, y = k_coord(image, (y, x, 1))\n",
    "        z, _, y2, _ = skeleton_side.joints[k].estimate\n",
    "        z, y2 = k_coord(image, (y2, z, 1))\n",
    "        # print(f\"Naive Bone matching: {skeleton_front.joints[k].name} [{x}, {y}, {z}]\")\n",
    "        homogenous_skeleton[k] = [x, y, z]\n",
    "    return homogenous_skeleton\n",
    "\n",
    "# Import dependencies\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "plotly.offline.init_notebook_mode()\n",
    "\n",
    "def plot_homogeneous_skeleton(hskeletonDict):\n",
    "    trace = go.Scatter3d(\n",
    "        x=[n[0] for n in list(hskeletonDict.values())] + [0, 1280],\n",
    "        y=[n[2] for n in list(hskeletonDict.values())] + [0, 1280],  # <-- Put your data instead\n",
    "        z=[1280-n[1]-(720) for n in list(hskeletonDict.values())] + [0, 720],  # <-- Put your data instead\n",
    "        mode='markers',\n",
    "        marker={\n",
    "            'size': 3,\n",
    "            'opacity': 0.8,\n",
    "        }\n",
    "    )\n",
    "    linetraces = []\n",
    "    for p1, p2 in KeypointEdges.keys():\n",
    "        linetrace = go.Scatter3d(\n",
    "            x=[n[1][0] for n in list(hskeletonDict.items()) if n[0] == p1 or n[0] == p2],\n",
    "            y=[n[1][2] for n in list(hskeletonDict.items()) if n[0] == p1 or n[0] == p2],  # <-- Put your data instead\n",
    "            z=[1280-n[1][1]-(720) for n in list(hskeletonDict.items()) if n[0] == p1 or n[0] == p2],  # <-- Put your data instead\n",
    "            mode='lines',\n",
    "            marker={\n",
    "                'size': 3,\n",
    "                'opacity': 0.8,\n",
    "            }\n",
    "        )\n",
    "        linetraces.append(linetrace)\n",
    "    layout = go.Layout(margin={'l': 0, 'r': 0, 'b': 0, 't': 0})\n",
    "    data = [trace] + linetraces\n",
    "    return data\n",
    "    plot_figure = go.Figure(data=data, layout=layout)\n",
    "    # Render the plot.\n",
    "    # plotly.offline.iplot(plot_figure)\n",
    "\n",
    "\n",
    "def plot_homogeneous_skeleton_animation(hskeletonDict_list):\n",
    "    frames = []\n",
    "    for hskeletonDict in hskeletonDict_list:\n",
    "        trace = go.Scatter3d(\n",
    "            x=[n[0] for n in list(hskeletonDict.values())] + [0, 1280],\n",
    "            y=[n[2] for n in list(hskeletonDict.values())] + [0, 1280],\n",
    "            z=[1280-n[1]-(720) for n in list(hskeletonDict.values())] + [0, 720],\n",
    "            mode='markers',\n",
    "            marker={\n",
    "                'size': 3,\n",
    "                'opacity': 0.8,\n",
    "            }\n",
    "        )\n",
    "        linetraces = []\n",
    "        for p1, p2 in KeypointEdges.keys():\n",
    "            linetrace = go.Scatter3d(\n",
    "                x=[n[1][0] for n in list(hskeletonDict.items()) if n[0] == p1 or n[0] == p2],\n",
    "                y=[n[1][2] for n in list(hskeletonDict.items()) if n[0] == p1 or n[0] == p2],\n",
    "                z=[1280-n[1][1]-(720) for n in list(hskeletonDict.items()) if n[0] == p1 or n[0] == p2],\n",
    "                mode='lines',\n",
    "                marker={\n",
    "                    'size': 3,\n",
    "                    'opacity': 0.8,\n",
    "                }\n",
    "            )\n",
    "            linetraces.append(linetrace)\n",
    "        \n",
    "        frame_data = [trace] + linetraces\n",
    "        frames.append(go.Frame(data=frame_data))\n",
    "    layout = go.Layout(\n",
    "        margin={'l': 0, 'r': 0, 'b': 0, 't': 0},\n",
    "        height=720,\n",
    "        updatemenus=[{\n",
    "            \"buttons\": [\n",
    "                {\"args\": [None, {\"frame\": {\"duration\": 30, \"redraw\": True}, \"fromcurrent\": True}],\n",
    "                 \"label\": \"Play\",\n",
    "                 \"method\": \"animate\"},\n",
    "                {\"args\": [[None], {\"frame\": {\"duration\": 0, \"redraw\": True}, \"mode\": \"immediate\", \"transition\": {\"duration\": 0}}],\n",
    "                 \"label\": \"Pause\",\n",
    "                 \"method\": \"animate\"}\n",
    "            ],\n",
    "            \"direction\": \"left\",\n",
    "            \"pad\": {\"r\": 10, \"t\": 87},\n",
    "            \"showactive\": False,\n",
    "            \"type\": \"buttons\",\n",
    "            \"x\": 0.1,\n",
    "            \"xanchor\": \"right\",\n",
    "            \"y\": 0,\n",
    "            \"yanchor\": \"top\"\n",
    "        }]\n",
    "    )\n",
    "    initial_data = plot_homogeneous_skeleton(hskeletonDict_list[0])\n",
    "    plot_figure = go.Figure(data=initial_data, layout=layout, frames=frames)\n",
    "    plot_figure.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis=dict(range=[0, 1280]),  # adjust x-axis range if necessary\n",
    "            yaxis=dict(range=[0, 1280]),  # adjust y-axis range if necessary\n",
    "            zaxis=dict(range=[0, 720]),  # adjust z-axis range if necessary\n",
    "        )\n",
    "    )\n",
    "    plotly.offline.iplot(plot_figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c08174-fda2-44f0-826b-deb9131ea1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mirage.skeleton import SkeletonDetection3D\n",
    "Skeleton3D = SkeletonDetection3D()\n",
    "h_skeletons = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f789585-72b8-43c0-bb22-b449fb247591",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(120):\n",
    "    imgs = process_and_viz_split(i_cam, ml_interface)\n",
    "    im_a, im_b = split_image_stack(imgs)\n",
    "    # show_images([im_a, im_b])\n",
    "    hskeleton = merge_skeleton(im_a, s_a, s_b)\n",
    "    h_skeletons.append(hskeleton)\n",
    "    Skeleton3D.update_predictions(hskeleton, (1.0 / i_cam.get_frame_rate_per_second()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2944238e-d94a-4577-a9a0-c235cd41996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_homogeneous_skeleton_animation(h_skeletons)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MirageEnv",
   "language": "python",
   "name": "mirageenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
